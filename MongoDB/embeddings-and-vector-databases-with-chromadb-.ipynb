{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140b4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def prepare_car_reviews_data(\n",
    "    data_path: pathlib.Path, vehicle_years: list[int] = [2017]\n",
    "):\n",
    "    \"\"\"Prepare the car reviews dataset for ChromaDB\"\"\"\n",
    "\n",
    "    # Define the schema to ensure proper data types are enforced\n",
    "    dtypes = {\n",
    "        \"\": pl.Int64,\n",
    "        \"Review_Date\": pl.Utf8,\n",
    "        \"Author_Name\": pl.Utf8,\n",
    "        \"Vehicle_Title\": pl.Utf8,\n",
    "        \"Review_Title\": pl.Utf8,\n",
    "        \"Review\": pl.Utf8,\n",
    "        \"Rating\": pl.Float64,\n",
    "    }\n",
    "\n",
    "    # Scan the car reviews dataset(s)\n",
    "    car_reviews = pl.scan_csv(data_path, dtypes=dtypes)\n",
    "\n",
    "    # Extract the vehicle title and year as new columns\n",
    "    # Filter on selected years\n",
    "    car_review_db_data = (\n",
    "        car_reviews.with_columns(\n",
    "            [\n",
    "                (\n",
    "                    pl.col(\"Vehicle_Title\")\n",
    "                    .str.split(by=\" \")\n",
    "                    .list.get(0)\n",
    "                    .cast(pl.Int64)\n",
    "                ).alias(\"Vehicle_Year\"),\n",
    "                (pl.col(\"Vehicle_Title\").str.split(by=\" \").list.get(1)).alias(\n",
    "                    \"Vehicle_Model\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        .filter(pl.col(\"Vehicle_Year\").is_in(vehicle_years))\n",
    "        .select(\n",
    "            [\n",
    "                \"Review_Title\",\n",
    "                \"Review\",\n",
    "                \"Rating\",\n",
    "                \"Vehicle_Year\",\n",
    "                \"Vehicle_Model\",\n",
    "            ]\n",
    "        )\n",
    "        .sort([\"Vehicle_Model\", \"Rating\"])\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    # Create ids, documents, and metadatas data in the format chromadb expects\n",
    "    ids = [f\"review{i}\" for i in range(car_review_db_data.shape[0])]\n",
    "    documents = car_review_db_data[\"Review\"].to_list()\n",
    "    metadatas = car_review_db_data.drop(\"Review\").to_dicts()\n",
    "\n",
    "    return {\"ids\": ids, \"documents\": documents, \"metadatas\": metadatas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a289f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from more_itertools import batched\n",
    "\n",
    "\n",
    "def build_chroma_collection(\n",
    "    chroma_path: pathlib.Path,\n",
    "    collection_name: str,\n",
    "    embedding_func_name: str,\n",
    "    ids: list[str],\n",
    "    documents: list[str],\n",
    "    metadatas: list[dict],\n",
    "    distance_func_name: str = \"cosine\",\n",
    "):\n",
    "    \"\"\"Create a ChromaDB collection\"\"\"\n",
    "\n",
    "    chroma_client = chromadb.PersistentClient(chroma_path)\n",
    "\n",
    "    embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name=embedding_func_name\n",
    "    )\n",
    "\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=embedding_func,\n",
    "        metadata={\"hnsw:space\": distance_func_name},\n",
    "    )\n",
    "\n",
    "    document_indices = list(range(len(documents)))\n",
    "\n",
    "    for batch in batched(document_indices, 166):\n",
    "        start_idx = batch[0]\n",
    "        end_idx = batch[-1]\n",
    "\n",
    "        collection.add(\n",
    "            ids=ids[start_idx:end_idx],\n",
    "            documents=documents[start_idx:end_idx],\n",
    "            metadatas=metadatas[start_idx:end_idx],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c6da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_cosine_similarity(u: np.ndarray, v: np.ndarray) -> float:\n",
    "    \"\"\"Compute the cosine similarity between two vectors\"\"\"\n",
    "\n",
    "    return (u @ v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ee7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhaoj\\OneDrive - The University of Chicago\\Desktop\\materials-embeddings-and-vector-databases-with-chromadb-\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # 查看当前工作目录\n",
    "os.chdir(\"C:/Users/zhaoj/OneDrive - The University of Chicago/Desktop/materials-embeddings-and-vector-databases-with-chromadb-\")  # 切换到正确目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f8fd6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chroma_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcar_data_etl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prepare_car_reviews_data\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchroma_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_chroma_collection\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m embedding_functions\n\u001b[32m      6\u001b[39m DATA_PATH = \u001b[33m\"\u001b[39m\u001b[33mdata/archive/*\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'chroma_utils'"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from car_data_etl import prepare_car_reviews_data\n",
    "from chroma_utils import build_chroma_collection\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "DATA_PATH = \"data/archive/*\"\n",
    "CHROMA_PATH = \"car_review_embeddings\"\n",
    "EMBEDDING_FUNC_NAME = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "COLLECTION_NAME = \"car_reviews\"\n",
    "\n",
    "chroma_car_reviews_dict = prepare_car_reviews_data(DATA_PATH)\n",
    "\n",
    "build_chroma_collection(\n",
    "    CHROMA_PATH,\n",
    "    COLLECTION_NAME,\n",
    "    EMBEDDING_FUNC_NAME,\n",
    "    chroma_car_reviews_dict[\"ids\"],\n",
    "    chroma_car_reviews_dict[\"documents\"],\n",
    "    chroma_car_reviews_dict[\"metadatas\"],\n",
    ")\n",
    "\n",
    "client = chromadb.PersistentClient(CHROMA_PATH)\n",
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=EMBEDDING_FUNC_NAME\n",
    ")\n",
    "collection = client.get_collection(\n",
    "    name=COLLECTION_NAME, embedding_function=embedding_func\n",
    ")\n",
    "\n",
    "great_reviews = collection.query(\n",
    "    query_texts=[\n",
    "        \"Find me some positive reviews that discuss the car's performance\"\n",
    "    ],\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"distances\", \"metadatas\"],\n",
    ")\n",
    "\n",
    "print(great_reviews[\"documents\"][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e2cd55",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cosine_similarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcosine_similarity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_cosine_similarity\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load the medium-size English model\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cosine_similarity'"
     ]
    }
   ],
   "source": [
    "from cosine_similarity import compute_cosine_similarity\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the medium-size English model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Get the word vector for the word \"dog\"\n",
    "dog_embedding = nlp.vocab[\"dog\"].vector\n",
    "\n",
    "# Word vectors are stored as NumPy arrays\n",
    "print(type(dog_embedding))\n",
    "\n",
    "# Word vector dimension\n",
    "print(dog_embedding.shape)\n",
    "\n",
    "# First 10 elements of the \"dog\" word vector\n",
    "print(dog_embedding[0:10])\n",
    "\n",
    "dog_embedding = nlp.vocab[\"dog\"].vector\n",
    "cat_embedding = nlp.vocab[\"cat\"].vector\n",
    "apple_embedding = nlp.vocab[\"apple\"].vector\n",
    "tasty_embedding = nlp.vocab[\"tasty\"].vector\n",
    "delicious_embedding = nlp.vocab[\"delicious\"].vector\n",
    "truck_embedding = nlp.vocab[\"truck\"].vector\n",
    "\n",
    "print(compute_cosine_similarity(dog_embedding, cat_embedding))\n",
    "\n",
    "print(compute_cosine_similarity(delicious_embedding, tasty_embedding))\n",
    "\n",
    "print(compute_cosine_similarity(apple_embedding, delicious_embedding))\n",
    "\n",
    "print(compute_cosine_similarity(dog_embedding, apple_embedding))\n",
    "\n",
    "print(compute_cosine_similarity(truck_embedding, delicious_embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbcaff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosine_similarity import compute_cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "texts = [\n",
    "    \"The canine barked loudly.\",\n",
    "    \"The dog made a noisy bark.\",\n",
    "    \"He ate a lot of pizza.\",\n",
    "    \"He devoured a large quantity of pizza pie.\",\n",
    "]\n",
    "\n",
    "text_embeddings = model.encode(texts)\n",
    "\n",
    "print(type(text_embeddings))\n",
    "\n",
    "print(text_embeddings.shape)\n",
    "\n",
    "text_embeddings_dict = dict(zip(texts, list(text_embeddings)))\n",
    "\n",
    "dog_text_1 = \"The canine barked loudly.\"\n",
    "dog_text_2 = \"The dog made a noisy bark.\"\n",
    "print(\n",
    "    compute_cosine_similarity(\n",
    "        text_embeddings_dict[dog_text_1], text_embeddings_dict[dog_text_2]\n",
    "    )\n",
    ")\n",
    "\n",
    "pizza_text_1 = \"He ate a lot of pizza.\"\n",
    "pizza_text_2 = \"He devoured a large quantity of pizza pie.\"\n",
    "print(\n",
    "    compute_cosine_similarity(\n",
    "        text_embeddings_dict[pizza_text_1], text_embeddings_dict[pizza_text_2]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    compute_cosine_similarity(\n",
    "        text_embeddings_dict[dog_text_1], text_embeddings_dict[pizza_text_1]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b14329a",
   "metadata": {},
   "source": [
    "car review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28342518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import chromadb\n",
    "import openai\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "DATA_PATH = \"data/archive/*\"\n",
    "CHROMA_PATH = \"car_review_embeddings\"\n",
    "EMBEDDING_FUNC_NAME = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "COLLECTION_NAME = \"car_reviews\"\n",
    "\n",
    "with open(\"config.json\", \"r\") as json_file:\n",
    "    config_data = json.load(json_file)\n",
    "\n",
    "openai.api_key = config_data.get(\"openai-secret-key\")\n",
    "\n",
    "client = chromadb.PersistentClient(CHROMA_PATH)\n",
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=EMBEDDING_FUNC_NAME\n",
    ")\n",
    "\n",
    "collection = client.get_collection(\n",
    "    name=COLLECTION_NAME, embedding_function=embedding_func\n",
    ")\n",
    "\n",
    "context = \"\"\"\n",
    " You are a customer success employee at a large\n",
    "  car dealership. Use the following car reviews\n",
    "  to answer questions: {}\n",
    " \"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    " What's the key to great customer satisfaction\n",
    "  based on detailed positive reviews?\n",
    " \"\"\"\n",
    "\n",
    "good_reviews = collection.query(\n",
    "    query_texts=[question],\n",
    "    n_results=10,\n",
    "    include=[\"documents\"],\n",
    "    where={\"Rating\": {\"$gte\": 3}},\n",
    ")\n",
    "\n",
    "reviews_str = \",\".join(good_reviews[\"documents\"][0])\n",
    "\n",
    "good_review_summaries = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context.format(reviews_str)},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "reviews_str = \",\".join(good_reviews[\"documents\"][0])\n",
    "\n",
    "print(\"Good reviews: \")\n",
    "print(reviews_str)\n",
    "print(\"###########################################\")\n",
    "\n",
    "good_review_summaries = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context.format(reviews_str)},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "print(\"AI-Generated summary of good reviews: \")\n",
    "print(good_review_summaries[\"choices\"][0][\"message\"][\"content\"])\n",
    "print(\"###########################################\")\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "          You are a customer success employee at a large car dealership.\n",
    "          Use the following car reivews to answer questions: {}\n",
    "          \"\"\"\n",
    "question = \"\"\"\n",
    "            Which of these poor reviews has the worst implications about\n",
    "            our dealership? Explain why.\n",
    "            \"\"\"\n",
    "\n",
    "poor_reviews = collection.query(\n",
    "    query_texts=[question],\n",
    "    n_results=5,\n",
    "    include=[\"documents\"],\n",
    "    where={\"Rating\": {\"$lte\": 3}},\n",
    ")\n",
    "\n",
    "reviews_str = \",\".join(poor_reviews[\"documents\"][0])\n",
    "\n",
    "print(\"Worst reviews: \")\n",
    "print(poor_reviews[\"documents\"][0][0])\n",
    "print(\"###########################################\")\n",
    "\n",
    "poor_review_analysis = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": context.format(reviews_str)},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "print(\"AI-Generated summary of the single worst review: \")\n",
    "print(poor_review_analysis[\"choices\"][0][\"message\"][\"content\"])\n",
    "print(\"###########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12ae0023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[0 1]\n",
      "(2,)\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "0\n",
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create vectors with NumPy\n",
    "vector1 = np.array([1, 0])\n",
    "vector2 = np.array([0, 1])\n",
    "print(vector1)\n",
    "print(vector2)\n",
    "\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([0, 1])\n",
    "v3 = np.array([np.sqrt(2), np.sqrt(2)])\n",
    "\n",
    "# Dimension\n",
    "print(v1.shape)\n",
    "\n",
    "# Magnitude\n",
    "print(np.sqrt(np.sum(v1**2)))\n",
    "print(np.linalg.norm(v1))\n",
    "print(np.linalg.norm(v3))\n",
    "\n",
    "# Dot product\n",
    "print(np.sum(v1 * v2))\n",
    "print(v1 @ v3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
